{"version":3,"file":"component---src-pages-smol-strats-js-545fbb26ebe8319635e9.js","mappings":"6HAuBA,IApBA,SAAkBA,GAAmD,IAAlD,KAAEC,EAAI,SAAEC,EAAQ,SAAEC,GAAW,EAAK,UAAEC,GAAWJ,EAChE,OAAIG,EAEAE,EAAAA,cAACC,EAAAA,KAAI,CAACC,GAAIN,EAAMG,UAAS,iCAAmCA,GACzDF,GAKLG,EAAAA,cAAA,KACEJ,KAAMA,EACNO,QAASL,GAAY,SACrBM,IAAI,sBACJL,UAAS,iCAAmCA,GAE3CF,EAGP,C,4FCrBA,EAAe,IAA0B,+DCAzC,EAAe,IAA0B,oECgFzC,MA3EA,WACE,OACEG,EAAAA,cAAA,QAAMD,UAAU,0BACdC,EAAAA,cAAA,OAAKD,UAAU,gDACbC,EAAAA,cAAA,WACEA,EAAAA,cAAA,MAAID,UAAU,4CAA2C,kEAGzDC,EAAAA,cAAA,KAAGD,UAAU,iCAAgC,cAC/B,IACZC,EAAAA,cAACK,EAAAA,EAAS,CAACT,KAAM,oCAAoC,sBAExC,IAAI,SACV,IACPI,EAAAA,cAACK,EAAAA,EAAS,CACRT,KACE,gEAEH,yBAEY,IAAI,8JAKnBI,EAAAA,cAAA,OAAKD,UAAU,8BACbC,EAAAA,cAACK,EAAAA,EAAS,CACRT,KAAK,kGACLG,UAAU,QACX,cAKLC,EAAAA,cAAA,SAAOM,UAAQ,EAACP,UAAU,QACxBC,EAAAA,cAAA,UAAQO,IAAKC,EAAkBC,KAAK,eAEtCT,EAAAA,cAAA,KAAGD,UAAU,iCACXC,EAAAA,cAAA,SAAG,cAAc,wFACoB,IACrCA,EAAAA,cAACK,EAAAA,EAAS,CACRT,KACE,0EAEH,gBAEW,88BAiBdI,EAAAA,cAAA,KAAGD,UAAU,iCAAgC,oGAI7CC,EAAAA,cAAA,SAAOM,UAAQ,EAACP,UAAU,QACxBC,EAAAA,cAAA,UAAQO,IAAKG,EAAcD,KAAK,gBAK1C,C","sources":["webpack://leguru/./src/components/Hyperlink.js","webpack://leguru/./src/videos/m1-spiral-policy.mp4","webpack://leguru/./src/videos/m1-spiral-policy-path.mp4","webpack://leguru/./src/pages/smol-strats.js"],"sourcesContent":["import { Link } from \"gatsby\";\nimport * as React from \"react\";\n\nfunction Hyperlink({ href, children, samePage = false, className }) {\n  if (samePage) {\n    return (\n      <Link to={href} className={`text-primary hover:opacity-50 ${className}`}>\n        {children}\n      </Link>\n    );\n  }\n  return (\n    <a\n      href={href}\n      target={!samePage && \"_blank\"}\n      rel=\"noopener noreferrer\"\n      className={`text-primary hover:opacity-50 ${className}`}\n    >\n      {children}\n    </a>\n  );\n}\n\nexport default Hyperlink;\n","export default __webpack_public_path__ + \"static/m1-spiral-policy-ce6ff7e02bb56ab3393f8cd8633ca25b.mp4\";","export default __webpack_public_path__ + \"static/m1-spiral-policy-path-e6ebbf1316c0500a046627fa1092c1fc.mp4\";","import * as React from \"react\";\nimport Hyperlink from \"../components/Hyperlink\";\nimport SpiralPolicy from \"../videos/m1-spiral-policy.mp4\";\nimport SpiralPolicyPath from \"../videos/m1-spiral-policy-path.mp4\";\n\nfunction SmolStrats() {\n  return (\n    <main className=\"bg-accent text-justify\">\n      <div className=\"container max-w-2xl mx-auto px-5 pt-10 pb-10\">\n        <div>\n          <h4 className=\"text-secondary text-3xl hover:opacity-50\">\n            Programmatic Reinforcement Learning (April 2023 - August 2023)\n          </h4>\n          <p className=\"text-accent-dark pt-5 text-lg\">\n            Worked with{\" \"}\n            <Hyperlink href={\"https://games-automata-play.com/\"}>\n              NathanaÃ«l Fijalkow\n            </Hyperlink>{\" \"}\n            at the{\" \"}\n            <Hyperlink\n              href={\n                \"https://www.mimuw.edu.pl/en/dziedziny-badan/teoria-automatow\"\n              }\n            >\n              automata theory group\n            </Hyperlink>{\" \"}\n            of the University of Warsaw on synthesizing programmatic policies\n            for markov decision processes (MDPs) by exploiting programmatic\n            representations of MDPs.\n          </p>\n          <div className=\"flex flex-row text-lg mt-1\">\n            <Hyperlink\n              href=\"https://github.com/guruprerana/guruprerana.github.io/raw/source/static/report-m1-internship.pdf\"\n              className=\"ml-1\"\n            >\n              [Report]\n            </Hyperlink>\n          </div>\n        </div>\n        <video controls className=\"mt-5\">\n          <source src={SpiralPolicyPath} type=\"video/mp4\" />\n        </video>\n        <p className=\"text-accent-dark pt-5 text-lg\">\n          <b>Abstract. </b>Starting from a programmatic representation of a\n          markov decision process (MDP) in the{\" \"}\n          <Hyperlink\n            href={\n              \"https://www.prismmodelchecker.org/manual/ThePRISMLanguage/Introduction\"\n            }\n          >\n            PRISM syntax\n          </Hyperlink>\n          , we examine the task of synthesizing a policy in the form of a\n          program for the MDP. The PRISM syntax allows us to specify MDPs\n          concisely by partitioning the state space into regions with similar\n          actions and transitions. While we cannot address the complete\n          expressive power of the PRISM syntax, we restrict ourselves to a small\n          subclass of two dimensional deterministic gridworlds partitioned into\n          regions along linear predicates. Using a relaxation of this class of\n          gridworlds, we present an algorithm to synthesize programmatic\n          policies which exploit the symmetries present in the representation of\n          the MDP. Our programs use memory to track subgoals and navigate\n          between the edges of regions to provide a concise representation of a\n          policy. Our main result is a proof of a concrete upper bound on the\n          size of the synthesized programs. We also give a practical\n          implementation of our synthesis algorithm which is evaluated on\n          randomly generated instances of gridworlds.\n        </p>\n        <p className=\"text-accent-dark pt-2 text-lg\">\n          A policy synthesized for a gridworld by our implementation can be\n          visualized in the video below.\n        </p>\n        <video controls className=\"mt-5\">\n          <source src={SpiralPolicy} type=\"video/mp4\" />\n        </video>\n      </div>\n    </main>\n  );\n}\n\nexport default SmolStrats;\n"],"names":["_ref","href","children","samePage","className","React","Link","to","target","rel","Hyperlink","controls","src","SpiralPolicyPath","type","SpiralPolicy"],"sourceRoot":""}